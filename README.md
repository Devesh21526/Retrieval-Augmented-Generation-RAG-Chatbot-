# Retrieval-Augmented-Generation-RAG-Chatbot

This project demonstrates how to build a Retrieval-Augmented Generation (RAG) application using LangChain, HuggingFaceHub, Chroma vector store, and HuggingFaceEmbeddings. With this setup, you can create intelligent chatbots that answer questions based on your custom data sources like books, documents, or knowledge bases.

ğŸ“Œ Example Use Case: Chat with AWS Documentation or Alice in Wonderland using RAG pipeline.

ğŸš€ Features
ğŸ§  Retrieval-Augmented Generation (RAG) pipeline

ğŸ” Semantic Search with vector embeddings

ğŸ“š Custom data sources (PDFs, text, markdown)

ğŸ”— Chroma for local vector database

ğŸ¤— HuggingFace Embeddings and LLM models via HuggingFaceHub

ğŸ§± Built with LangChain for modular and extensible design
