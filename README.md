# Retrieval-Augmented-Generation-RAG-Chatbot

This project demonstrates how to build a Retrieval-Augmented Generation (RAG) application using LangChain, HuggingFaceHub, Chroma vector store, and HuggingFaceEmbeddings. With this setup, you can create intelligent chatbots that answer questions based on your custom data sources like books, documents, or knowledge bases.

📌 Example Use Case: Chat with AWS Documentation or Alice in Wonderland using RAG pipeline.

🚀 Features
🧠 Retrieval-Augmented Generation (RAG) pipeline

🔍 Semantic Search with vector embeddings

📚 Custom data sources (PDFs, text, markdown)

🔗 Chroma for local vector database

🤗 HuggingFace Embeddings and LLM models via HuggingFaceHub

🧱 Built with LangChain for modular and extensible design
